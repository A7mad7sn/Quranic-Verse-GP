{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52caf821",
   "metadata": {},
   "source": [
    "# Data Combination for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d09cf12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tafsir</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>سورة الفاتحة سميت هذه السورة بالفاتحة؛ لأنه يف...</td>\n",
       "      <td>بِسۡمِ ٱللَّهِ ٱلرَّحۡمَٰنِ ٱلرَّحِيمِ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(الحَمْدُ للهِ رَبِّ العَالَمِينَ) الثناء على ...</td>\n",
       "      <td>ٱلۡحَمۡدُ لِلَّهِ رَبِّ ٱلۡعَٰلَمِينَ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(الرَّحْمَنِ) الذي وسعت رحمته جميع الخلق، (الر...</td>\n",
       "      <td>ٱلرَّحۡمَٰنِ ٱلرَّحِيمِ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>وهو سبحانه وحده مالك يوم القيامة، وهو يوم الجز...</td>\n",
       "      <td>مَٰلِكِ يَوۡمِ ٱلدِّينِ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>إنا نخصك وحدك بالعبادة، ونستعين بك وحدك في جمي...</td>\n",
       "      <td>إِيَّاكَ نَعۡبُدُ وَإِيَّاكَ نَسۡتَعِينُ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24939</th>\n",
       "      <td>ملك الناس، يتصرّف فيهم بما يشاء، لا ملك لهم غيره.</td>\n",
       "      <td>مَلِكِ ٱلنَّاسِ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24940</th>\n",
       "      <td>معبودهم بحقّ، لا معبود لهم بحق غيره.</td>\n",
       "      <td>إِلَٰهِ ٱلنَّاسِ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24941</th>\n",
       "      <td>من شرّ الشيطان الذي يلقي وسوسته إلى الإنسان إذ...</td>\n",
       "      <td>مِن شَرِّ ٱلۡوَسۡوَاسِ ٱلۡخَنَّاسِ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24942</th>\n",
       "      <td>يلقي بوسوسته إلى قلوب الناس.</td>\n",
       "      <td>ٱلَّذِي يُوَسۡوِسُ فِي صُدُورِ ٱلنَّاسِ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24943</th>\n",
       "      <td>وهو يكون من الإنس كما يكون من الجن.</td>\n",
       "      <td>مِنَ ٱلۡجِنَّةِ وَٱلنَّاسِ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24944 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tafsir  \\\n",
       "0      سورة الفاتحة سميت هذه السورة بالفاتحة؛ لأنه يف...   \n",
       "1      (الحَمْدُ للهِ رَبِّ العَالَمِينَ) الثناء على ...   \n",
       "2      (الرَّحْمَنِ) الذي وسعت رحمته جميع الخلق، (الر...   \n",
       "3      وهو سبحانه وحده مالك يوم القيامة، وهو يوم الجز...   \n",
       "4      إنا نخصك وحدك بالعبادة، ونستعين بك وحدك في جمي...   \n",
       "...                                                  ...   \n",
       "24939  ملك الناس، يتصرّف فيهم بما يشاء، لا ملك لهم غيره.   \n",
       "24940               معبودهم بحقّ، لا معبود لهم بحق غيره.   \n",
       "24941  من شرّ الشيطان الذي يلقي وسوسته إلى الإنسان إذ...   \n",
       "24942                       يلقي بوسوسته إلى قلوب الناس.   \n",
       "24943                وهو يكون من الإنس كما يكون من الجن.   \n",
       "\n",
       "                                           text  \n",
       "0        بِسۡمِ ٱللَّهِ ٱلرَّحۡمَٰنِ ٱلرَّحِيمِ  \n",
       "1         ٱلۡحَمۡدُ لِلَّهِ رَبِّ ٱلۡعَٰلَمِينَ  \n",
       "2                       ٱلرَّحۡمَٰنِ ٱلرَّحِيمِ  \n",
       "3                       مَٰلِكِ يَوۡمِ ٱلدِّينِ  \n",
       "4      إِيَّاكَ نَعۡبُدُ وَإِيَّاكَ نَسۡتَعِينُ  \n",
       "...                                         ...  \n",
       "24939                           مَلِكِ ٱلنَّاسِ  \n",
       "24940                          إِلَٰهِ ٱلنَّاسِ  \n",
       "24941        مِن شَرِّ ٱلۡوَسۡوَاسِ ٱلۡخَنَّاسِ  \n",
       "24942   ٱلَّذِي يُوَسۡوِسُ فِي صُدُورِ ٱلنَّاسِ  \n",
       "24943                مِنَ ٱلۡجِنَّةِ وَٱلنَّاسِ  \n",
       "\n",
       "[24944 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "base = 'D:\\Materials\\Graduation Project\\Implementation\\Search Model V5'\n",
    "\n",
    "df = pd.read_excel(base+'/full-tafsir.xlsx')\n",
    "\n",
    "model_df = pd.DataFrame()\n",
    "model_df['tafsir'] = (df['ar-muyassar-tanzil']._append(df['ar-jalalyn-tanzil']))._append(df['ar-al-baghawi-qurancom'])\n",
    "model_df['text'] = (df['text']._append(df['text']))._append(df['text'])\n",
    "\n",
    "test_df = pd.DataFrame()\n",
    "test_df['tafsir'] = df['ar-mokhtasar-islamhouse']\n",
    "test_df['text'] = df['text']\n",
    "\n",
    "merged_df = pd.concat([model_df, test_df], ignore_index=True)\n",
    "model_df = pd.DataFrame(merged_df)\n",
    "\n",
    "model_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3780963e",
   "metadata": {},
   "source": [
    "# Duplicates removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08ef4170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tafsir</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>سورة الفاتحة سميت هذه السورة بالفاتحة؛ لأنه يف...</td>\n",
       "      <td>بِسۡمِ ٱللَّهِ ٱلرَّحۡمَٰنِ ٱلرَّحِيمِ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(الحَمْدُ للهِ رَبِّ العَالَمِينَ) الثناء على ...</td>\n",
       "      <td>ٱلۡحَمۡدُ لِلَّهِ رَبِّ ٱلۡعَٰلَمِينَ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(الرَّحْمَنِ) الذي وسعت رحمته جميع الخلق، (الر...</td>\n",
       "      <td>ٱلرَّحۡمَٰنِ ٱلرَّحِيمِ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>وهو سبحانه وحده مالك يوم القيامة، وهو يوم الجز...</td>\n",
       "      <td>مَٰلِكِ يَوۡمِ ٱلدِّينِ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>إنا نخصك وحدك بالعبادة، ونستعين بك وحدك في جمي...</td>\n",
       "      <td>إِيَّاكَ نَعۡبُدُ وَإِيَّاكَ نَسۡتَعِينُ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24939</th>\n",
       "      <td>ملك الناس، يتصرّف فيهم بما يشاء، لا ملك لهم غيره.</td>\n",
       "      <td>مَلِكِ ٱلنَّاسِ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24940</th>\n",
       "      <td>معبودهم بحقّ، لا معبود لهم بحق غيره.</td>\n",
       "      <td>إِلَٰهِ ٱلنَّاسِ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24941</th>\n",
       "      <td>من شرّ الشيطان الذي يلقي وسوسته إلى الإنسان إذ...</td>\n",
       "      <td>مِن شَرِّ ٱلۡوَسۡوَاسِ ٱلۡخَنَّاسِ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24942</th>\n",
       "      <td>يلقي بوسوسته إلى قلوب الناس.</td>\n",
       "      <td>ٱلَّذِي يُوَسۡوِسُ فِي صُدُورِ ٱلنَّاسِ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24943</th>\n",
       "      <td>وهو يكون من الإنس كما يكون من الجن.</td>\n",
       "      <td>مِنَ ٱلۡجِنَّةِ وَٱلنَّاسِ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24726 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tafsir  \\\n",
       "0      سورة الفاتحة سميت هذه السورة بالفاتحة؛ لأنه يف...   \n",
       "1      (الحَمْدُ للهِ رَبِّ العَالَمِينَ) الثناء على ...   \n",
       "2      (الرَّحْمَنِ) الذي وسعت رحمته جميع الخلق، (الر...   \n",
       "3      وهو سبحانه وحده مالك يوم القيامة، وهو يوم الجز...   \n",
       "4      إنا نخصك وحدك بالعبادة، ونستعين بك وحدك في جمي...   \n",
       "...                                                  ...   \n",
       "24939  ملك الناس، يتصرّف فيهم بما يشاء، لا ملك لهم غيره.   \n",
       "24940               معبودهم بحقّ، لا معبود لهم بحق غيره.   \n",
       "24941  من شرّ الشيطان الذي يلقي وسوسته إلى الإنسان إذ...   \n",
       "24942                       يلقي بوسوسته إلى قلوب الناس.   \n",
       "24943                وهو يكون من الإنس كما يكون من الجن.   \n",
       "\n",
       "                                           text  \n",
       "0        بِسۡمِ ٱللَّهِ ٱلرَّحۡمَٰنِ ٱلرَّحِيمِ  \n",
       "1         ٱلۡحَمۡدُ لِلَّهِ رَبِّ ٱلۡعَٰلَمِينَ  \n",
       "2                       ٱلرَّحۡمَٰنِ ٱلرَّحِيمِ  \n",
       "3                       مَٰلِكِ يَوۡمِ ٱلدِّينِ  \n",
       "4      إِيَّاكَ نَعۡبُدُ وَإِيَّاكَ نَسۡتَعِينُ  \n",
       "...                                         ...  \n",
       "24939                           مَلِكِ ٱلنَّاسِ  \n",
       "24940                          إِلَٰهِ ٱلنَّاسِ  \n",
       "24941        مِن شَرِّ ٱلۡوَسۡوَاسِ ٱلۡخَنَّاسِ  \n",
       "24942   ٱلَّذِي يُوَسۡوِسُ فِي صُدُورِ ٱلنَّاسِ  \n",
       "24943                مِنَ ٱلۡجِنَّةِ وَٱلنَّاسِ  \n",
       "\n",
       "[24726 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df = model_df.drop_duplicates()\n",
    "\n",
    "model_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193f94e9",
   "metadata": {},
   "source": [
    "# Stop Words and Punctuation removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baabc5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tafsir</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>سورة الفاتحة سميت السورة بالفاتحة لأنه يفتتح ا...</td>\n",
       "      <td>بِسۡمِ ٱللَّهِ ٱلرَّحۡمَٰنِ ٱلرَّحِيمِ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>الحمد لله رب العالمين  الثناء الله بصفاته كله...</td>\n",
       "      <td>ٱلۡحَمۡدُ لِلَّهِ رَبِّ ٱلۡعَٰلَمِينَ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>الرحمن  وسعت رحمته الخلق  الرحيم   بالمؤمنين ...</td>\n",
       "      <td>ٱلرَّحۡمَٰنِ ٱلرَّحِيمِ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>سبحانه وحده مالك يوم القيامة يوم الجزاء الأعما...</td>\n",
       "      <td>مَٰلِكِ يَوۡمِ ٱلدِّينِ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>نخصك وحدك بالعبادة ونستعين وحدك أمورنا فالأمر ...</td>\n",
       "      <td>إِيَّاكَ نَعۡبُدُ وَإِيَّاكَ نَسۡتَعِينُ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24939</th>\n",
       "      <td>ملك الناس يتصرف فيهم يشاء ملك غيره</td>\n",
       "      <td>مَلِكِ ٱلنَّاسِ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24940</th>\n",
       "      <td>معبودهم بحق معبود بحق غيره</td>\n",
       "      <td>إِلَٰهِ ٱلنَّاسِ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24941</th>\n",
       "      <td>شر الشيطان يلقي وسوسته الإنسان غفل ذكر الله وي...</td>\n",
       "      <td>مِن شَرِّ ٱلۡوَسۡوَاسِ ٱلۡخَنَّاسِ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24942</th>\n",
       "      <td>يلقي بوسوسته قلوب الناس</td>\n",
       "      <td>ٱلَّذِي يُوَسۡوِسُ فِي صُدُورِ ٱلنَّاسِ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24943</th>\n",
       "      <td>يكون الإنس يكون الجن</td>\n",
       "      <td>مِنَ ٱلۡجِنَّةِ وَٱلنَّاسِ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24726 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tafsir  \\\n",
       "0      سورة الفاتحة سميت السورة بالفاتحة لأنه يفتتح ا...   \n",
       "1       الحمد لله رب العالمين  الثناء الله بصفاته كله...   \n",
       "2       الرحمن  وسعت رحمته الخلق  الرحيم   بالمؤمنين ...   \n",
       "3      سبحانه وحده مالك يوم القيامة يوم الجزاء الأعما...   \n",
       "4      نخصك وحدك بالعبادة ونستعين وحدك أمورنا فالأمر ...   \n",
       "...                                                  ...   \n",
       "24939                ملك الناس يتصرف فيهم يشاء ملك غيره    \n",
       "24940                        معبودهم بحق معبود بحق غيره    \n",
       "24941  شر الشيطان يلقي وسوسته الإنسان غفل ذكر الله وي...   \n",
       "24942                           يلقي بوسوسته قلوب الناس    \n",
       "24943                              يكون الإنس يكون الجن    \n",
       "\n",
       "                                           text  \n",
       "0        بِسۡمِ ٱللَّهِ ٱلرَّحۡمَٰنِ ٱلرَّحِيمِ  \n",
       "1         ٱلۡحَمۡدُ لِلَّهِ رَبِّ ٱلۡعَٰلَمِينَ  \n",
       "2                       ٱلرَّحۡمَٰنِ ٱلرَّحِيمِ  \n",
       "3                       مَٰلِكِ يَوۡمِ ٱلدِّينِ  \n",
       "4      إِيَّاكَ نَعۡبُدُ وَإِيَّاكَ نَسۡتَعِينُ  \n",
       "...                                         ...  \n",
       "24939                           مَلِكِ ٱلنَّاسِ  \n",
       "24940                          إِلَٰهِ ٱلنَّاسِ  \n",
       "24941        مِن شَرِّ ٱلۡوَسۡوَاسِ ٱلۡخَنَّاسِ  \n",
       "24942   ٱلَّذِي يُوَسۡوِسُ فِي صُدُورِ ٱلنَّاسِ  \n",
       "24943                مِنَ ٱلۡجِنَّةِ وَٱلنَّاسِ  \n",
       "\n",
       "[24726 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "arabic_Tashkeel = re.compile(\"\"\"\n",
    "                                ّ    | # Shadda\n",
    "                                َ    | # Fatha\n",
    "                                ً    | # Tanwin Fath\n",
    "                                ُ    | # Damma\n",
    "                                ٌ    | # Tanwin Damm\n",
    "                                ِ    | # Kasra\n",
    "                                ٍ    | # Tanwin Kasr\n",
    "                                ْ    | # Sukun\n",
    "                                ـ    | # Tatwil/Kashida\n",
    "                                ٓ    | # Maddah Above\n",
    "                                ٔ    | # Hamza Above\n",
    "                                ٕ    | # Hamza Below\n",
    "                                ٖ    | # Subscript Alef\n",
    "                                ٗ    | # Inverted Damma\n",
    "                                ٘    | # Mark Noon Ghunna\n",
    "                                ٙ    | # Inverted Damma Below\n",
    "                                ٚ    | # Mark Sideways Noon Ghunna\n",
    "                                ٛ    | # Kasra with Wavy Hamza Below\n",
    "                                ٜ    | # Fatha with Wavy Hamza Above\n",
    "                                ٝ    | # Fatha with Wavy Hamza Below\n",
    "                                ٞ    | # Fatha with Ring\n",
    "                                ٟ    | # Fatha with Dot Above\n",
    "                            \"\"\", re.VERBOSE)\n",
    "\n",
    "stop_words = set(stopwords.words('arabic'))\n",
    "\n",
    "# Training filtering\n",
    "cleaned_text = []\n",
    "for tafsir in model_df['tafsir']:\n",
    "    words = word_tokenize(tafsir)\n",
    "\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words and not any(char.isdigit() for char in word)]\n",
    "\n",
    "    filtered_text = ' '.join(filtered_words)\n",
    "\n",
    "    arabic_punctuation = string.punctuation + '؛،؟«»'\n",
    "\n",
    "    translator = str.maketrans('', '', arabic_punctuation)\n",
    "    filtered_text = filtered_text.translate(translator)\n",
    "\n",
    "    filtered_text = re.sub(arabic_Tashkeel, '', filtered_text)\n",
    "\n",
    "    cleaned_text.append(filtered_text)\n",
    "\n",
    "model_df['tafsir'] = cleaned_text\n",
    "\n",
    "model_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1fa01d",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e61042f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T13:41:59.088610Z",
     "iopub.status.busy": "2024-04-02T13:41:59.088187Z",
     "iopub.status.idle": "2024-04-02T13:42:04.171288Z",
     "shell.execute_reply": "2024-04-02T13:42:04.170109Z",
     "shell.execute_reply.started": "2024-04-02T13:41:59.088560Z"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "aborted",
     "timestamp": 1707222292530,
     "user": {
      "displayName": "Ahmed Hassan",
      "userId": "14194593192757951982"
     },
     "user_tz": -120
    },
    "id": "a9843910"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "\n",
      "WARNING: You are on Windows. If you detect any issue with pandarallel, be sure you checked out the Troubleshooting page:\n",
      "https://nalepae.github.io/pandarallel/troubleshooting/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tafsir</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>سورة فاتح سما سورة فاتح أن افتتح قرآن عظيم أسم...</td>\n",
       "      <td>بِسۡمِ ٱللَّهِ ٱلرَّحۡمَٰنِ ٱلرَّحِيمِ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>حمد له رب عالم ثناء الله صف كل أوصاف كمال نعم ...</td>\n",
       "      <td>ٱلۡحَمۡدُ لِلَّهِ رَبِّ ٱلۡعَٰلَمِينَ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>رحمن وسع رحمة خلق رحيم مؤمن هما اسم أسماء الله...</td>\n",
       "      <td>ٱلرَّحۡمَٰنِ ٱلرَّحِيمِ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>سبحان وحد مال يوم قيام يوم جزاء أعمال في قراء ...</td>\n",
       "      <td>مَٰلِكِ يَوۡمِ ٱلدِّينِ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>خاص وحد عباد استعان وحد أمور أمر كل بيد ملك مث...</td>\n",
       "      <td>إِيَّاكَ نَعۡبُدُ وَإِيَّاكَ نَسۡتَعِينُ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24721</th>\n",
       "      <td>ملك ناس تصرف في شاء ملك غير</td>\n",
       "      <td>مَلِكِ ٱلنَّاسِ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24722</th>\n",
       "      <td>معبود حق معبود حق غير</td>\n",
       "      <td>إِلَٰهِ ٱلنَّاسِ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24723</th>\n",
       "      <td>شر شيطان يلق سوس إنس غفل ذكر الله تأخر عن ذكر</td>\n",
       "      <td>مِن شَرِّ ٱلۡوَسۡوَاسِ ٱلۡخَنَّاسِ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24724</th>\n",
       "      <td>يلق وسوسة قلوب ناس</td>\n",
       "      <td>ٱلَّذِي يُوَسۡوِسُ فِي صُدُورِ ٱلنَّاسِ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24725</th>\n",
       "      <td>كوى إنس كوى جن</td>\n",
       "      <td>مِنَ ٱلۡجِنَّةِ وَٱلنَّاسِ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24726 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tafsir  \\\n",
       "0      سورة فاتح سما سورة فاتح أن افتتح قرآن عظيم أسم...   \n",
       "1      حمد له رب عالم ثناء الله صف كل أوصاف كمال نعم ...   \n",
       "2      رحمن وسع رحمة خلق رحيم مؤمن هما اسم أسماء الله...   \n",
       "3      سبحان وحد مال يوم قيام يوم جزاء أعمال في قراء ...   \n",
       "4      خاص وحد عباد استعان وحد أمور أمر كل بيد ملك مث...   \n",
       "...                                                  ...   \n",
       "24721                        ملك ناس تصرف في شاء ملك غير   \n",
       "24722                              معبود حق معبود حق غير   \n",
       "24723      شر شيطان يلق سوس إنس غفل ذكر الله تأخر عن ذكر   \n",
       "24724                                 يلق وسوسة قلوب ناس   \n",
       "24725                                     كوى إنس كوى جن   \n",
       "\n",
       "                                           text  \n",
       "0        بِسۡمِ ٱللَّهِ ٱلرَّحۡمَٰنِ ٱلرَّحِيمِ  \n",
       "1         ٱلۡحَمۡدُ لِلَّهِ رَبِّ ٱلۡعَٰلَمِينَ  \n",
       "2                       ٱلرَّحۡمَٰنِ ٱلرَّحِيمِ  \n",
       "3                       مَٰلِكِ يَوۡمِ ٱلدِّينِ  \n",
       "4      إِيَّاكَ نَعۡبُدُ وَإِيَّاكَ نَسۡتَعِينُ  \n",
       "...                                         ...  \n",
       "24721                           مَلِكِ ٱلنَّاسِ  \n",
       "24722                          إِلَٰهِ ٱلنَّاسِ  \n",
       "24723        مِن شَرِّ ٱلۡوَسۡوَاسِ ٱلۡخَنَّاسِ  \n",
       "24724   ٱلَّذِي يُوَسۡوِسُ فِي صُدُورِ ٱلنَّاسِ  \n",
       "24725                مِنَ ٱلۡجِنَّةِ وَٱلنَّاسِ  \n",
       "\n",
       "[24726 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True,nb_workers=8)\n",
    "\n",
    "def lemmatize_text(tafsir):\n",
    "    import qalsadi.lemmatizer\n",
    "    lemmer = qalsadi.lemmatizer.Lemmatizer()\n",
    "    lemmas = lemmer.lemmatize_text(tafsir)\n",
    "    return \" \".join(lemmas)\n",
    "\n",
    "if os.path.exists(base+'/Lemmatized Data.xlsx'):\n",
    "    model_df = pd.read_excel(base+'/Lemmatized Data.xlsx')\n",
    "else:    \n",
    "    model_df['tafsir'] = model_df['tafsir'].parallel_apply(lemmatize_text)\n",
    "    model_df.to_excel(base+'/Lemmatized Data.xlsx',index=False)\n",
    "    \n",
    "model_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520a313a",
   "metadata": {},
   "source": [
    "# Eliminating High Fequency words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37684c47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T13:42:04.174699Z",
     "iopub.status.busy": "2024-04-02T13:42:04.173512Z",
     "iopub.status.idle": "2024-04-02T13:42:34.420226Z",
     "shell.execute_reply": "2024-04-02T13:42:34.419074Z",
     "shell.execute_reply.started": "2024-04-02T13:42:04.174653Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24726, 2)\n",
      "(6236, 2)\n",
      "18206\n",
      "high_freq_words\n",
      "---------------\n",
      "{'قول', 'أن', 'رب', 'رسول', 'من', 'على', 'قال', 'خبر', 'عبد', 'بن', 'سلم', 'صلى', 'الله'}\n",
      "18148\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tafsir</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>سورة فاتح سما سورة فاتح افتتح قرآن عظيم أسمى م...</td>\n",
       "      <td>بِسۡمِ ٱللَّهِ ٱلرَّحۡمَٰنِ ٱلرَّحِيمِ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>حمد له عالم ثناء صف كل أوصاف كمال نعم ظاهر باط...</td>\n",
       "      <td>ٱلۡحَمۡدُ لِلَّهِ رَبِّ ٱلۡعَٰلَمِينَ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>رحمن وسع رحمة خلق رحيم مؤمن هما اسم أسماء تعالى</td>\n",
       "      <td>ٱلرَّحۡمَٰنِ ٱلرَّحِيمِ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>سبحان وحد مال يوم قيام يوم جزاء أعمال قراء مسل...</td>\n",
       "      <td>مَٰلِكِ يَوۡمِ ٱلدِّينِ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>خاص وحد عباد استعان وحد أمور أمر كل بيد ملك مث...</td>\n",
       "      <td>إِيَّاكَ نَعۡبُدُ وَإِيَّاكَ نَسۡتَعِينُ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24721</th>\n",
       "      <td>ملك ناس تصرف شاء ملك غير</td>\n",
       "      <td>مَلِكِ ٱلنَّاسِ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24722</th>\n",
       "      <td>معبود حق معبود حق غير</td>\n",
       "      <td>إِلَٰهِ ٱلنَّاسِ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24723</th>\n",
       "      <td>شر شيطان يلق سوس إنس غفل ذكر تأخر ذكر</td>\n",
       "      <td>مِن شَرِّ ٱلۡوَسۡوَاسِ ٱلۡخَنَّاسِ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24724</th>\n",
       "      <td>يلق وسوسة قلوب ناس</td>\n",
       "      <td>ٱلَّذِي يُوَسۡوِسُ فِي صُدُورِ ٱلنَّاسِ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24725</th>\n",
       "      <td>كوى إنس كوى جن</td>\n",
       "      <td>مِنَ ٱلۡجِنَّةِ وَٱلنَّاسِ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24726 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tafsir  \\\n",
       "0      سورة فاتح سما سورة فاتح افتتح قرآن عظيم أسمى م...   \n",
       "1      حمد له عالم ثناء صف كل أوصاف كمال نعم ظاهر باط...   \n",
       "2        رحمن وسع رحمة خلق رحيم مؤمن هما اسم أسماء تعالى   \n",
       "3      سبحان وحد مال يوم قيام يوم جزاء أعمال قراء مسل...   \n",
       "4      خاص وحد عباد استعان وحد أمور أمر كل بيد ملك مث...   \n",
       "...                                                  ...   \n",
       "24721                           ملك ناس تصرف شاء ملك غير   \n",
       "24722                              معبود حق معبود حق غير   \n",
       "24723              شر شيطان يلق سوس إنس غفل ذكر تأخر ذكر   \n",
       "24724                                 يلق وسوسة قلوب ناس   \n",
       "24725                                     كوى إنس كوى جن   \n",
       "\n",
       "                                           text  \n",
       "0        بِسۡمِ ٱللَّهِ ٱلرَّحۡمَٰنِ ٱلرَّحِيمِ  \n",
       "1         ٱلۡحَمۡدُ لِلَّهِ رَبِّ ٱلۡعَٰلَمِينَ  \n",
       "2                       ٱلرَّحۡمَٰنِ ٱلرَّحِيمِ  \n",
       "3                       مَٰلِكِ يَوۡمِ ٱلدِّينِ  \n",
       "4      إِيَّاكَ نَعۡبُدُ وَإِيَّاكَ نَسۡتَعِينُ  \n",
       "...                                         ...  \n",
       "24721                           مَلِكِ ٱلنَّاسِ  \n",
       "24722                          إِلَٰهِ ٱلنَّاسِ  \n",
       "24723        مِن شَرِّ ٱلۡوَسۡوَاسِ ٱلۡخَنَّاسِ  \n",
       "24724   ٱلَّذِي يُوَسۡوِسُ فِي صُدُورِ ٱلنَّاسِ  \n",
       "24725                مِنَ ٱلۡجِنَّةِ وَٱلنَّاسِ  \n",
       "\n",
       "[24726 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "print(model_df.shape)\n",
    "print(test_df.shape)\n",
    "\n",
    "\n",
    "def count_words(df, column):\n",
    "    all_words = []\n",
    "    for text in df[column]:\n",
    "        tokens = word_tokenize(text)\n",
    "        all_words.extend(tokens)\n",
    "    word_counts = Counter(all_words)\n",
    "    return word_counts\n",
    "\n",
    "# Count words in model_df\n",
    "model_word_counts = count_words(model_df, 'tafsir')\n",
    "print(len(model_word_counts))\n",
    "\n",
    "# Determine high-frequency words to remove (for example, let's say words appearing more than 100 times are considered high-frequency)\n",
    "high_freq_words = {word for word, count in model_word_counts.items() if count > 6000}\n",
    "print(\"high_freq_words\")\n",
    "print(\"---------------\")\n",
    "print(high_freq_words)\n",
    "\n",
    "# Ensuring to remove some stop words after lemmatization\n",
    "# إنشاء قائمة لحروف الجر العربية\n",
    "حروف_الجر = [\"إلى\", \"عن\", \"من\", \"في\", \"على\", \"مع\", \"ب\", \"ل\", \"ك\", \"حتى\", \"منذ\", \"إلا\", \"عدا\"]\n",
    "\n",
    "# إنشاء قائمة لحروف العطف\n",
    "حروف_العطف = [\"و\", \"أو\", \"بل\", \"إذا\", \"لكن\", \"لذلك\", \"فإن\", \"حيث\", \"أيضاً\", \"ثم\", \"بينما\", \"حتى\", \"إما\"]\n",
    "\n",
    "# إنشاء قائمة لظروف الزمان\n",
    "ظروف_الزمان = [\"الآن\", \"ثم\", \"منذ\", \"مرة\", \"مبكراً\", \"فجأة\", \"مساء\", \"صباحاً\", \"غداً\", \"أمس\"]\n",
    "\n",
    "# إنشاء قائمة لظروف المكان\n",
    "ظروف_المكان = [\"هنا\", \"هناك\", \"فيها\", \"بعيداً\", \"قرب\", \"فوق\", \"تحت\", \"جانب\", \"داخل\", \"خارج\"]\n",
    "\n",
    "# إنشاء قائمة لأدوات التوكيد\n",
    "ادوات_التوكيد = [\"لكن\", \"إنما\", \"إذا\", \"أن\", \"كأن\", \"لعل\", \"حتى\", \"حين\", \"إلا\", \"عسى\", \"مثل\"]\n",
    "\n",
    "# إنشاء قائمة لحروف النسخ\n",
    "حروف_النسخ = [\"أن\", \"لم\", \"لا\", \"لن\", \"إن\", \"ليت\", \"لو\", \"لعل\", \"كي\", \"إذا\", \"حتى\"]\n",
    "\n",
    "# قائمة تضم كل الكلمات\n",
    "كل_كلمات_التوقف = حروف_الجر + حروف_العطف + ظروف_الزمان + ظروف_المكان + ادوات_التوكيد + حروف_النسخ\n",
    "\n",
    "# Function to remove high-frequency words from text\n",
    "def remove_high_freq_words(text, high_freq_words):\n",
    "    tokens = word_tokenize(text)\n",
    "    filtered_tokens = [token for token in tokens if token not in high_freq_words and token not in كل_كلمات_التوقف]\n",
    "    filtered_text = ' '.join(filtered_tokens)\n",
    "    return filtered_text\n",
    "\n",
    "# Remove high-frequency words from 'tafsir' column in both DataFrames\n",
    "model_df['tafsir'] = model_df['tafsir'].apply(lambda x: remove_high_freq_words(x, high_freq_words))\n",
    "\n",
    "# Count words in model_df\n",
    "model_word_counts = count_words(model_df, 'tafsir')\n",
    "print(len(model_word_counts))\n",
    "\n",
    "model_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6d0b8d",
   "metadata": {},
   "source": [
    "# Augmentation & N_grams Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fc23009",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T13:42:34.422391Z",
     "iopub.status.busy": "2024-04-02T13:42:34.421994Z",
     "iopub.status.idle": "2024-04-02T13:42:46.229910Z",
     "shell.execute_reply": "2024-04-02T13:42:46.228653Z",
     "shell.execute_reply.started": "2024-04-02T13:42:34.422360Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tafsir</th>\n",
       "      <th>text</th>\n",
       "      <th>n_grams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>سورة فاتح سما سورة فاتح افتتح قرآن عظيم أسمى م...</td>\n",
       "      <td>بِسۡمِ ٱللَّهِ ٱلرَّحۡمَٰنِ ٱلرَّحِيمِ</td>\n",
       "      <td>سورة فاتح سما سورة فاتح</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>سورة فاتح سما سورة فاتح افتتح قرآن عظيم أسمى م...</td>\n",
       "      <td>بِسۡمِ ٱللَّهِ ٱلرَّحۡمَٰنِ ٱلرَّحِيمِ</td>\n",
       "      <td>فاتح سما سورة فاتح افتتح</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>سورة فاتح سما سورة فاتح افتتح قرآن عظيم أسمى م...</td>\n",
       "      <td>بِسۡمِ ٱللَّهِ ٱلرَّحۡمَٰنِ ٱلرَّحِيمِ</td>\n",
       "      <td>سما سورة فاتح افتتح قرآن</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>سورة فاتح سما سورة فاتح افتتح قرآن عظيم أسمى م...</td>\n",
       "      <td>بِسۡمِ ٱللَّهِ ٱلرَّحۡمَٰنِ ٱلرَّحِيمِ</td>\n",
       "      <td>سورة فاتح افتتح قرآن عظيم</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>سورة فاتح سما سورة فاتح افتتح قرآن عظيم أسمى م...</td>\n",
       "      <td>بِسۡمِ ٱللَّهِ ٱلرَّحۡمَٰنِ ٱلرَّحِيمِ</td>\n",
       "      <td>فاتح افتتح قرآن عظيم أسمى</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723100</th>\n",
       "      <td>شر شيطان يلق سوس إنس غفل ذكر تأخر ذكر</td>\n",
       "      <td>مِن شَرِّ ٱلۡوَسۡوَاسِ ٱلۡخَنَّاسِ</td>\n",
       "      <td>يلق سوس إنس غفل ذكر</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723101</th>\n",
       "      <td>شر شيطان يلق سوس إنس غفل ذكر تأخر ذكر</td>\n",
       "      <td>مِن شَرِّ ٱلۡوَسۡوَاسِ ٱلۡخَنَّاسِ</td>\n",
       "      <td>سوس إنس غفل ذكر تأخر</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723102</th>\n",
       "      <td>شر شيطان يلق سوس إنس غفل ذكر تأخر ذكر</td>\n",
       "      <td>مِن شَرِّ ٱلۡوَسۡوَاسِ ٱلۡخَنَّاسِ</td>\n",
       "      <td>إنس غفل ذكر تأخر ذكر</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723103</th>\n",
       "      <td>يلق وسوسة قلوب ناس</td>\n",
       "      <td>ٱلَّذِي يُوَسۡوِسُ فِي صُدُورِ ٱلنَّاسِ</td>\n",
       "      <td>يلق وسوسة قلوب ناس</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723104</th>\n",
       "      <td>كوى إنس كوى جن</td>\n",
       "      <td>مِنَ ٱلۡجِنَّةِ وَٱلنَّاسِ</td>\n",
       "      <td>كوى إنس كوى جن</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>723105 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tafsir  \\\n",
       "0       سورة فاتح سما سورة فاتح افتتح قرآن عظيم أسمى م...   \n",
       "1       سورة فاتح سما سورة فاتح افتتح قرآن عظيم أسمى م...   \n",
       "2       سورة فاتح سما سورة فاتح افتتح قرآن عظيم أسمى م...   \n",
       "3       سورة فاتح سما سورة فاتح افتتح قرآن عظيم أسمى م...   \n",
       "4       سورة فاتح سما سورة فاتح افتتح قرآن عظيم أسمى م...   \n",
       "...                                                   ...   \n",
       "723100              شر شيطان يلق سوس إنس غفل ذكر تأخر ذكر   \n",
       "723101              شر شيطان يلق سوس إنس غفل ذكر تأخر ذكر   \n",
       "723102              شر شيطان يلق سوس إنس غفل ذكر تأخر ذكر   \n",
       "723103                                 يلق وسوسة قلوب ناس   \n",
       "723104                                     كوى إنس كوى جن   \n",
       "\n",
       "                                           text                    n_grams  \n",
       "0        بِسۡمِ ٱللَّهِ ٱلرَّحۡمَٰنِ ٱلرَّحِيمِ    سورة فاتح سما سورة فاتح  \n",
       "1        بِسۡمِ ٱللَّهِ ٱلرَّحۡمَٰنِ ٱلرَّحِيمِ   فاتح سما سورة فاتح افتتح  \n",
       "2        بِسۡمِ ٱللَّهِ ٱلرَّحۡمَٰنِ ٱلرَّحِيمِ   سما سورة فاتح افتتح قرآن  \n",
       "3        بِسۡمِ ٱللَّهِ ٱلرَّحۡمَٰنِ ٱلرَّحِيمِ  سورة فاتح افتتح قرآن عظيم  \n",
       "4        بِسۡمِ ٱللَّهِ ٱلرَّحۡمَٰنِ ٱلرَّحِيمِ  فاتح افتتح قرآن عظيم أسمى  \n",
       "...                                         ...                        ...  \n",
       "723100       مِن شَرِّ ٱلۡوَسۡوَاسِ ٱلۡخَنَّاسِ        يلق سوس إنس غفل ذكر  \n",
       "723101       مِن شَرِّ ٱلۡوَسۡوَاسِ ٱلۡخَنَّاسِ       سوس إنس غفل ذكر تأخر  \n",
       "723102       مِن شَرِّ ٱلۡوَسۡوَاسِ ٱلۡخَنَّاسِ       إنس غفل ذكر تأخر ذكر  \n",
       "723103  ٱلَّذِي يُوَسۡوِسُ فِي صُدُورِ ٱلنَّاسِ         يلق وسوسة قلوب ناس  \n",
       "723104               مِنَ ٱلۡجِنَّةِ وَٱلنَّاسِ             كوى إنس كوى جن  \n",
       "\n",
       "[723105 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def generate_5_grams(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    if len(tokens) < 5:\n",
    "        return text\n",
    "    else:\n",
    "        five_grams = [' '.join(gram) for gram in ngrams(tokens, 5)]\n",
    "        return five_grams\n",
    "\n",
    "model_df['n_grams'] = model_df['tafsir'].apply(generate_5_grams)\n",
    "\n",
    "\n",
    "model_df =  model_df.explode('n_grams')\n",
    "model_df = model_df.drop_duplicates()\n",
    "model_df = model_df.dropna()\n",
    "\n",
    "model_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "model_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a482317b",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d97adc88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T13:42:46.233820Z",
     "iopub.status.busy": "2024-04-02T13:42:46.233040Z",
     "iopub.status.idle": "2024-04-02T13:42:46.440214Z",
     "shell.execute_reply": "2024-04-02T13:42:46.438892Z",
     "shell.execute_reply.started": "2024-04-02T13:42:46.233775Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "402724    خَٰلِدِينَ فِيهَا مَا دَامَتِ ٱلسَّمَٰوَٰتُ وَ...\n",
       "696637    فَإِذَا رَكِبُواْ فِي ٱلۡفُلۡكِ دَعَوُاْ ٱللَّ...\n",
       "100202    وَضَرَبَ ٱللَّهُ مَثَلٗا لِّلَّذِينَ ءَامَنُوا...\n",
       "336062    مَا جَعَلَ ٱللَّهُ مِنۢ بَحِيرَةٖ وَلَا سَآئِ...\n",
       "32315     ٱلتَّـٰٓئِبُونَ ٱلۡعَٰبِدُونَ ٱلۡحَٰمِدُونَ ٱل...\n",
       "                                ...                        \n",
       "406435    يُوسُفُ أَعۡرِضۡ عَنۡ هَٰذَاۚ وَٱسۡتَغۡفِرِي ل...\n",
       "410161    فَبَدَأَ بِأَوۡعِيَتِهِمۡ قَبۡلَ وِعَآءِ أَخِ...\n",
       "49516     وَنَسُوقُ ٱلۡمُجۡرِمِينَ إِلَىٰ جَهَنَّمَ وِرۡدٗا\n",
       "420010    رَّبَّنَآ إِنِّيٓ أَسۡكَنتُ مِن ذُرِّيَّتِي ب...\n",
       "171504    وَمَنۡ أَظۡلَمُ مِمَّن ذُكِّرَ بِـَٔايَٰتِ رَب...\n",
       "Name: text, Length: 72311, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = model_df['n_grams']\n",
    "y = model_df['text']  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1,random_state=42)\n",
    "\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299a795a",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cbe2a14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T13:42:46.441865Z",
     "iopub.status.busy": "2024-04-02T13:42:46.441483Z",
     "iopub.status.idle": "2024-04-02T13:43:35.107992Z",
     "shell.execute_reply": "2024-04-02T13:43:35.106244Z",
     "shell.execute_reply.started": "2024-04-02T13:42:46.441835Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 787,   30, 1117,   38,   68],\n",
       "       [1472,  269,  333,  153,  923],\n",
       "       [ 534, 4685,   90, 2942,  128],\n",
       "       ...,\n",
       "       [1409,   90, 1409,  175,   43],\n",
       "       [ 101,  698,  420, 3452,  699],\n",
       "       [ 229,  162,   21,   22,  337]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "# Saving the Tokenizer\n",
    "import pickle\n",
    "with open(base+'/tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "sequences = tokenizer.texts_to_sequences(X_train)\n",
    "max_length = max(len(seq) for seq in sequences)\n",
    "\n",
    "def feature_extraction(X,tokenizer):\n",
    "    sequences = tokenizer.texts_to_sequences(X)\n",
    "    print(max_length)\n",
    "    padded_sequences = pad_sequences(sequences, maxlen=max_length)\n",
    "    return padded_sequences\n",
    "\n",
    "X_train = feature_extraction(X_train,tokenizer)\n",
    "X_test = feature_extraction(X_test,tokenizer)\n",
    "\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d82727",
   "metadata": {},
   "source": [
    "# One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "936f9362",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T13:43:35.111216Z",
     "iopub.status.busy": "2024-04-02T13:43:35.110092Z",
     "iopub.status.idle": "2024-04-02T13:43:40.228837Z",
     "shell.execute_reply": "2024-04-02T13:43:40.227434Z",
     "shell.execute_reply.started": "2024-04-02T13:43:35.111152Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72311, 6062)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pickle\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "y_train = encoder.fit_transform(np.array(y_train).reshape(-1, 1))\n",
    "y_test = encoder.transform(np.array(y_test).reshape(-1, 1))\n",
    "\n",
    "# Save the encoder to a file using pickle\n",
    "with open(base+'/onehot_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(encoder, f)\n",
    "\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8613a517",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f1b8c7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T13:43:40.231060Z",
     "iopub.status.busy": "2024-04-02T13:43:40.230659Z",
     "iopub.status.idle": "2024-04-02T13:43:40.331043Z",
     "shell.execute_reply": "2024-04-02T13:43:40.329449Z",
     "shell.execute_reply.started": "2024-04-02T13:43:40.231027Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ softmax (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Softmax</span>)                    │ ?                           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ softmax (\u001b[38;5;33mSoftmax\u001b[0m)                    │ ?                           │               \u001b[38;5;34m0\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense ,Input,Dropout,Softmax\n",
    "\n",
    "num_classes = y_train.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(input_dim=max(tokenizer.index_word.keys())+1, output_dim=200))\n",
    "model.add(LSTM(units=264, dropout=0.2, recurrent_dropout=0.2,activation='tanh'))  # Adding dropout\n",
    "model.add(Dense(units=num_classes))\n",
    "model.add(Softmax(axis=-1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27c8ce9",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7e333e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T13:43:40.333041Z",
     "iopub.status.busy": "2024-04-02T13:43:40.332578Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m662s\u001b[0m 101ms/step - accuracy: 0.0284 - loss: 7.4777 - val_accuracy: 0.2396 - val_loss: 4.4889\n",
      "Epoch 2/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m633s\u001b[0m 97ms/step - accuracy: 0.2987 - loss: 3.9715 - val_accuracy: 0.4199 - val_loss: 3.0046\n",
      "Epoch 3/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m657s\u001b[0m 101ms/step - accuracy: 0.4703 - loss: 2.6529 - val_accuracy: 0.5102 - val_loss: 2.3383\n",
      "Epoch 4/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m611s\u001b[0m 94ms/step - accuracy: 0.5636 - loss: 2.0173 - val_accuracy: 0.5698 - val_loss: 1.9530\n",
      "Epoch 5/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m623s\u001b[0m 96ms/step - accuracy: 0.6260 - loss: 1.6369 - val_accuracy: 0.6084 - val_loss: 1.7168\n",
      "Epoch 6/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m618s\u001b[0m 95ms/step - accuracy: 0.6671 - loss: 1.4006 - val_accuracy: 0.6356 - val_loss: 1.5597\n",
      "Epoch 7/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m613s\u001b[0m 94ms/step - accuracy: 0.6982 - loss: 1.2342 - val_accuracy: 0.6576 - val_loss: 1.4485\n",
      "Epoch 8/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m618s\u001b[0m 95ms/step - accuracy: 0.7214 - loss: 1.1162 - val_accuracy: 0.6741 - val_loss: 1.3618\n",
      "Epoch 9/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m624s\u001b[0m 96ms/step - accuracy: 0.7390 - loss: 1.0233 - val_accuracy: 0.6848 - val_loss: 1.2935\n",
      "Epoch 10/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m638s\u001b[0m 98ms/step - accuracy: 0.7539 - loss: 0.9534 - val_accuracy: 0.6946 - val_loss: 1.2514\n",
      "Epoch 11/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m620s\u001b[0m 95ms/step - accuracy: 0.7631 - loss: 0.9046 - val_accuracy: 0.7038 - val_loss: 1.2064\n",
      "Epoch 12/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m649s\u001b[0m 100ms/step - accuracy: 0.7722 - loss: 0.8603 - val_accuracy: 0.7085 - val_loss: 1.1799\n",
      "Epoch 13/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m637s\u001b[0m 98ms/step - accuracy: 0.7809 - loss: 0.8195 - val_accuracy: 0.7154 - val_loss: 1.1569\n",
      "Epoch 14/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m633s\u001b[0m 97ms/step - accuracy: 0.7867 - loss: 0.7930 - val_accuracy: 0.7207 - val_loss: 1.1369\n",
      "Epoch 15/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m653s\u001b[0m 100ms/step - accuracy: 0.7914 - loss: 0.7684 - val_accuracy: 0.7243 - val_loss: 1.1225\n",
      "Epoch 16/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m649s\u001b[0m 100ms/step - accuracy: 0.7955 - loss: 0.7472 - val_accuracy: 0.7279 - val_loss: 1.1070\n",
      "Epoch 17/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m642s\u001b[0m 99ms/step - accuracy: 0.8007 - loss: 0.7264 - val_accuracy: 0.7302 - val_loss: 1.0992\n",
      "Epoch 18/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m658s\u001b[0m 101ms/step - accuracy: 0.8042 - loss: 0.7094 - val_accuracy: 0.7335 - val_loss: 1.0856\n",
      "Epoch 19/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m642s\u001b[0m 99ms/step - accuracy: 0.8074 - loss: 0.6941 - val_accuracy: 0.7353 - val_loss: 1.0765\n",
      "Epoch 20/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m631s\u001b[0m 97ms/step - accuracy: 0.8093 - loss: 0.6846 - val_accuracy: 0.7371 - val_loss: 1.0749\n",
      "Epoch 21/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m652s\u001b[0m 100ms/step - accuracy: 0.8140 - loss: 0.6661 - val_accuracy: 0.7419 - val_loss: 1.0625\n",
      "Epoch 22/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m643s\u001b[0m 99ms/step - accuracy: 0.8157 - loss: 0.6579 - val_accuracy: 0.7417 - val_loss: 1.0504\n",
      "Epoch 23/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m633s\u001b[0m 97ms/step - accuracy: 0.8170 - loss: 0.6516 - val_accuracy: 0.7422 - val_loss: 1.0609\n",
      "Epoch 24/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m652s\u001b[0m 100ms/step - accuracy: 0.8200 - loss: 0.6399 - val_accuracy: 0.7455 - val_loss: 1.0478\n",
      "Epoch 25/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m625s\u001b[0m 96ms/step - accuracy: 0.8215 - loss: 0.6310 - val_accuracy: 0.7471 - val_loss: 1.0484\n",
      "Epoch 26/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m652s\u001b[0m 100ms/step - accuracy: 0.8232 - loss: 0.6219 - val_accuracy: 0.7463 - val_loss: 1.0458\n",
      "Epoch 27/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m647s\u001b[0m 99ms/step - accuracy: 0.8254 - loss: 0.6150 - val_accuracy: 0.7461 - val_loss: 1.0494\n",
      "Epoch 28/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m639s\u001b[0m 98ms/step - accuracy: 0.8268 - loss: 0.6085 - val_accuracy: 0.7481 - val_loss: 1.0416\n",
      "Epoch 29/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m655s\u001b[0m 101ms/step - accuracy: 0.8288 - loss: 0.6007 - val_accuracy: 0.7496 - val_loss: 1.0316\n",
      "Epoch 30/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m648s\u001b[0m 100ms/step - accuracy: 0.8295 - loss: 0.5956 - val_accuracy: 0.7493 - val_loss: 1.0348\n",
      "Epoch 31/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m701s\u001b[0m 108ms/step - accuracy: 0.8302 - loss: 0.5931 - val_accuracy: 0.7511 - val_loss: 1.0320\n",
      "Epoch 32/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m663s\u001b[0m 102ms/step - accuracy: 0.8330 - loss: 0.5832 - val_accuracy: 0.7519 - val_loss: 1.0288\n",
      "Epoch 33/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m673s\u001b[0m 103ms/step - accuracy: 0.8330 - loss: 0.5835 - val_accuracy: 0.7529 - val_loss: 1.0282\n",
      "Epoch 34/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m659s\u001b[0m 101ms/step - accuracy: 0.8335 - loss: 0.5775 - val_accuracy: 0.7533 - val_loss: 1.0252\n",
      "Epoch 35/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m663s\u001b[0m 102ms/step - accuracy: 0.8357 - loss: 0.5693 - val_accuracy: 0.7546 - val_loss: 1.0207\n",
      "Epoch 36/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m697s\u001b[0m 107ms/step - accuracy: 0.8352 - loss: 0.5711 - val_accuracy: 0.7551 - val_loss: 1.0185\n",
      "Epoch 37/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m646s\u001b[0m 99ms/step - accuracy: 0.8378 - loss: 0.5605 - val_accuracy: 0.7554 - val_loss: 1.0126\n",
      "Epoch 38/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m650s\u001b[0m 100ms/step - accuracy: 0.8375 - loss: 0.5622 - val_accuracy: 0.7577 - val_loss: 1.0121\n",
      "Epoch 39/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m666s\u001b[0m 102ms/step - accuracy: 0.8390 - loss: 0.5552 - val_accuracy: 0.7583 - val_loss: 1.0125\n",
      "Epoch 40/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m680s\u001b[0m 104ms/step - accuracy: 0.8394 - loss: 0.5529 - val_accuracy: 0.7591 - val_loss: 1.0088\n",
      "Epoch 41/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m646s\u001b[0m 99ms/step - accuracy: 0.8392 - loss: 0.5525 - val_accuracy: 0.7592 - val_loss: 1.0034\n",
      "Epoch 42/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m658s\u001b[0m 101ms/step - accuracy: 0.8411 - loss: 0.5458 - val_accuracy: 0.7596 - val_loss: 1.0040\n",
      "Epoch 43/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m646s\u001b[0m 99ms/step - accuracy: 0.8402 - loss: 0.5461 - val_accuracy: 0.7604 - val_loss: 1.0100\n",
      "Epoch 44/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m654s\u001b[0m 100ms/step - accuracy: 0.8416 - loss: 0.5433 - val_accuracy: 0.7598 - val_loss: 1.0077\n",
      "Epoch 45/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m667s\u001b[0m 103ms/step - accuracy: 0.8431 - loss: 0.5373 - val_accuracy: 0.7597 - val_loss: 1.0067\n",
      "Epoch 46/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m726s\u001b[0m 111ms/step - accuracy: 0.8439 - loss: 0.5364 - val_accuracy: 0.7605 - val_loss: 1.0022\n",
      "Epoch 47/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m652s\u001b[0m 100ms/step - accuracy: 0.8437 - loss: 0.5355 - val_accuracy: 0.7619 - val_loss: 1.0070\n",
      "Epoch 48/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m733s\u001b[0m 113ms/step - accuracy: 0.8436 - loss: 0.5328 - val_accuracy: 0.7611 - val_loss: 1.0065\n",
      "Epoch 49/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m640s\u001b[0m 98ms/step - accuracy: 0.8448 - loss: 0.5300 - val_accuracy: 0.7627 - val_loss: 1.0034\n",
      "Epoch 50/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m623s\u001b[0m 96ms/step - accuracy: 0.8451 - loss: 0.5285 - val_accuracy: 0.7630 - val_loss: 1.0016\n",
      "Epoch 51/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m729s\u001b[0m 112ms/step - accuracy: 0.8465 - loss: 0.5246 - val_accuracy: 0.7634 - val_loss: 1.0043\n",
      "Epoch 52/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m634s\u001b[0m 97ms/step - accuracy: 0.8461 - loss: 0.5258 - val_accuracy: 0.7644 - val_loss: 0.9990\n",
      "Epoch 53/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m636s\u001b[0m 98ms/step - accuracy: 0.8463 - loss: 0.5255 - val_accuracy: 0.7628 - val_loss: 0.9993\n",
      "Epoch 54/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m665s\u001b[0m 102ms/step - accuracy: 0.8477 - loss: 0.5218 - val_accuracy: 0.7622 - val_loss: 1.0006\n",
      "Epoch 55/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m638s\u001b[0m 98ms/step - accuracy: 0.8458 - loss: 0.5233 - val_accuracy: 0.7646 - val_loss: 0.9988\n",
      "Epoch 56/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m641s\u001b[0m 98ms/step - accuracy: 0.8477 - loss: 0.5186 - val_accuracy: 0.7646 - val_loss: 0.9957\n",
      "Epoch 57/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m679s\u001b[0m 104ms/step - accuracy: 0.8479 - loss: 0.5165 - val_accuracy: 0.7661 - val_loss: 0.9961\n",
      "Epoch 58/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m642s\u001b[0m 99ms/step - accuracy: 0.8494 - loss: 0.5132 - val_accuracy: 0.7656 - val_loss: 0.9923\n",
      "Epoch 59/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m631s\u001b[0m 97ms/step - accuracy: 0.8488 - loss: 0.5133 - val_accuracy: 0.7660 - val_loss: 0.9946\n",
      "Epoch 60/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m649s\u001b[0m 100ms/step - accuracy: 0.8491 - loss: 0.5115 - val_accuracy: 0.7671 - val_loss: 0.9934\n",
      "Epoch 61/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m632s\u001b[0m 97ms/step - accuracy: 0.8504 - loss: 0.5073 - val_accuracy: 0.7657 - val_loss: 0.9931\n",
      "Epoch 62/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m654s\u001b[0m 100ms/step - accuracy: 0.8500 - loss: 0.5093 - val_accuracy: 0.7664 - val_loss: 0.9918\n",
      "Epoch 63/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m742s\u001b[0m 114ms/step - accuracy: 0.8505 - loss: 0.5076 - val_accuracy: 0.7673 - val_loss: 0.9901\n",
      "Epoch 64/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m661s\u001b[0m 101ms/step - accuracy: 0.8505 - loss: 0.5057 - val_accuracy: 0.7674 - val_loss: 0.9956\n",
      "Epoch 65/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m654s\u001b[0m 100ms/step - accuracy: 0.8517 - loss: 0.5000 - val_accuracy: 0.7678 - val_loss: 0.9889\n",
      "Epoch 66/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m679s\u001b[0m 104ms/step - accuracy: 0.8513 - loss: 0.5013 - val_accuracy: 0.7679 - val_loss: 0.9967\n",
      "Epoch 67/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m660s\u001b[0m 101ms/step - accuracy: 0.8517 - loss: 0.5004 - val_accuracy: 0.7662 - val_loss: 0.9968\n",
      "Epoch 68/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m661s\u001b[0m 101ms/step - accuracy: 0.8521 - loss: 0.4995 - val_accuracy: 0.7694 - val_loss: 0.9893\n",
      "Epoch 69/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m732s\u001b[0m 112ms/step - accuracy: 0.8518 - loss: 0.4999 - val_accuracy: 0.7681 - val_loss: 0.9918\n",
      "Epoch 70/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m733s\u001b[0m 113ms/step - accuracy: 0.8522 - loss: 0.4987 - val_accuracy: 0.7690 - val_loss: 0.9907\n",
      "Epoch 71/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m668s\u001b[0m 102ms/step - accuracy: 0.8536 - loss: 0.4958 - val_accuracy: 0.7686 - val_loss: 0.9862\n",
      "Epoch 72/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m690s\u001b[0m 106ms/step - accuracy: 0.8519 - loss: 0.5004 - val_accuracy: 0.7707 - val_loss: 0.9892\n",
      "Epoch 73/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m698s\u001b[0m 107ms/step - accuracy: 0.8537 - loss: 0.4954 - val_accuracy: 0.7683 - val_loss: 0.9936\n",
      "Epoch 74/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m688s\u001b[0m 106ms/step - accuracy: 0.8527 - loss: 0.4955 - val_accuracy: 0.7695 - val_loss: 0.9926\n",
      "Epoch 75/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m684s\u001b[0m 105ms/step - accuracy: 0.8542 - loss: 0.4907 - val_accuracy: 0.7696 - val_loss: 0.9923\n",
      "Epoch 76/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m755s\u001b[0m 116ms/step - accuracy: 0.8531 - loss: 0.4917 - val_accuracy: 0.7685 - val_loss: 0.9937\n",
      "Epoch 77/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m679s\u001b[0m 104ms/step - accuracy: 0.8534 - loss: 0.4939 - val_accuracy: 0.7694 - val_loss: 0.9913\n",
      "Epoch 78/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m678s\u001b[0m 104ms/step - accuracy: 0.8536 - loss: 0.4921 - val_accuracy: 0.7708 - val_loss: 0.9888\n",
      "Epoch 79/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m704s\u001b[0m 108ms/step - accuracy: 0.8535 - loss: 0.4927 - val_accuracy: 0.7699 - val_loss: 0.9836\n",
      "Epoch 80/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m696s\u001b[0m 107ms/step - accuracy: 0.8549 - loss: 0.4892 - val_accuracy: 0.7705 - val_loss: 0.9915\n",
      "Epoch 81/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m694s\u001b[0m 107ms/step - accuracy: 0.8545 - loss: 0.4900 - val_accuracy: 0.7707 - val_loss: 0.9852\n",
      "Epoch 82/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m672s\u001b[0m 103ms/step - accuracy: 0.8542 - loss: 0.4902 - val_accuracy: 0.7705 - val_loss: 0.9837\n",
      "Epoch 83/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m745s\u001b[0m 115ms/step - accuracy: 0.8558 - loss: 0.4854 - val_accuracy: 0.7701 - val_loss: 0.9857\n",
      "Epoch 84/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m690s\u001b[0m 106ms/step - accuracy: 0.8559 - loss: 0.4844 - val_accuracy: 0.7714 - val_loss: 0.9817\n",
      "Epoch 85/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m662s\u001b[0m 102ms/step - accuracy: 0.8543 - loss: 0.4913 - val_accuracy: 0.7725 - val_loss: 0.9833\n",
      "Epoch 86/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m689s\u001b[0m 106ms/step - accuracy: 0.8558 - loss: 0.4849 - val_accuracy: 0.7719 - val_loss: 0.9858\n",
      "Epoch 87/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m676s\u001b[0m 104ms/step - accuracy: 0.8553 - loss: 0.4861 - val_accuracy: 0.7724 - val_loss: 0.9838\n",
      "Epoch 88/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m673s\u001b[0m 103ms/step - accuracy: 0.8551 - loss: 0.4872 - val_accuracy: 0.7718 - val_loss: 0.9889\n",
      "Epoch 89/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m685s\u001b[0m 105ms/step - accuracy: 0.8556 - loss: 0.4845 - val_accuracy: 0.7721 - val_loss: 0.9859\n",
      "Epoch 90/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m694s\u001b[0m 107ms/step - accuracy: 0.8559 - loss: 0.4804 - val_accuracy: 0.7735 - val_loss: 0.9870\n",
      "Epoch 91/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m696s\u001b[0m 107ms/step - accuracy: 0.8562 - loss: 0.4825 - val_accuracy: 0.7719 - val_loss: 0.9850\n",
      "Epoch 92/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m680s\u001b[0m 104ms/step - accuracy: 0.8563 - loss: 0.4826 - val_accuracy: 0.7723 - val_loss: 0.9861\n",
      "Epoch 93/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m724s\u001b[0m 111ms/step - accuracy: 0.8563 - loss: 0.4812 - val_accuracy: 0.7726 - val_loss: 0.9869\n",
      "Epoch 94/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m681s\u001b[0m 104ms/step - accuracy: 0.8571 - loss: 0.4800 - val_accuracy: 0.7731 - val_loss: 0.9807\n",
      "Epoch 95/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m675s\u001b[0m 104ms/step - accuracy: 0.8558 - loss: 0.4809 - val_accuracy: 0.7735 - val_loss: 0.9866\n",
      "Epoch 96/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m694s\u001b[0m 107ms/step - accuracy: 0.8564 - loss: 0.4806 - val_accuracy: 0.7730 - val_loss: 0.9795\n",
      "Epoch 97/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m688s\u001b[0m 106ms/step - accuracy: 0.8573 - loss: 0.4776 - val_accuracy: 0.7734 - val_loss: 0.9814\n",
      "Epoch 98/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m631s\u001b[0m 97ms/step - accuracy: 0.8570 - loss: 0.4798 - val_accuracy: 0.7723 - val_loss: 0.9883\n",
      "Epoch 99/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m664s\u001b[0m 102ms/step - accuracy: 0.8572 - loss: 0.4789 - val_accuracy: 0.7724 - val_loss: 0.9895\n",
      "Epoch 100/100\n",
      "\u001b[1m6508/6508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m642s\u001b[0m 99ms/step - accuracy: 0.8571 - loss: 0.4788 - val_accuracy: 0.7722 - val_loss: 0.9863\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2449b666110>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "from keras.utils import Sequence\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, X, y, batch_size):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.X) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        start_idx = index * self.batch_size\n",
    "        end_idx = min((index + 1) * self.batch_size, len(self.X))\n",
    "        batch_X = self.X[start_idx:end_idx]\n",
    "        batch_y = self.y[start_idx:end_idx]\n",
    "        return batch_X, batch_y\n",
    "\n",
    "generator = DataGenerator(X_train, y_train, batch_size=100)\n",
    "\n",
    "model.fit(generator, epochs=100,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67235ee",
   "metadata": {},
   "source": [
    "# Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3fe1118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2260/2260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7721646775732599\n",
      "Precision:  0.7911082331302487\n",
      "Recall:  0.7721646775732599\n",
      "F1 Score:  0.7729207951026738\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score,accuracy_score\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert predicted probabilities to binary labels\n",
    "y_pred_binary = np.argmax(y_pred, axis=1)\n",
    "y_test_binary = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Calculate accuracy,precision, recall, and F1 score\n",
    "accuracy = accuracy_score(y_test_binary, y_pred_binary)\n",
    "precision = precision_score(y_test_binary, y_pred_binary, average='weighted')\n",
    "recall = recall_score(y_test_binary, y_pred_binary, average='weighted')\n",
    "f1 = f1_score(y_test_binary, y_pred_binary, average='weighted')\n",
    "print(\"Accuracy: \",accuracy)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)\n",
    "\n",
    "# Saving the model\n",
    "model.save(base+'/Lstm_model_100epochs.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a390d74f",
   "metadata": {},
   "source": [
    "# Test Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "468b158e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your input : معصية قوم ما لله و اصطيادهم يوم حرم الصيد\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step\n",
      "1  -->  وَرَفَعۡنَا فَوۡقَهُمُ ٱلطُّورَ بِمِيثَٰقِهِمۡ وَقُلۡنَا لَهُمُ ٱدۡخُلُواْ ٱلۡبَابَ سُجَّدٗا وَقُلۡنَا لَهُمۡ لَا تَعۡدُواْ فِي ٱلسَّبۡتِ وَأَخَذۡنَا مِنۡهُم مِّيثَٰقًا غَلِيظٗا\n",
      "\n",
      "2  -->  وَلَقَدۡ عَلِمۡتُمُ ٱلَّذِينَ ٱعۡتَدَوۡاْ مِنكُمۡ فِي ٱلسَّبۡتِ فَقُلۡنَا لَهُمۡ كُونُواْ قِرَدَةً خَٰسِـِٔينَ\n",
      "\n",
      "3  -->  وَأَنتَ حِلُّۢ بِهَٰذَا ٱلۡبَلَدِ\n",
      "\n",
      "4  -->  وَسۡـَٔلۡهُمۡ عَنِ ٱلۡقَرۡيَةِ ٱلَّتِي كَانَتۡ حَاضِرَةَ ٱلۡبَحۡرِ إِذۡ يَعۡدُونَ فِي ٱلسَّبۡتِ إِذۡ تَأۡتِيهِمۡ حِيتَانُهُمۡ يَوۡمَ سَبۡتِهِمۡ شُرَّعٗا وَيَوۡمَ لَا يَسۡبِتُونَ لَا تَأۡتِيهِمۡۚ كَذَٰلِكَ نَبۡلُوهُم بِمَا كَانُواْ يَفۡسُقُونَ\n",
      "\n",
      "5  -->  لِّيَشۡهَدُواْ مَنَٰفِعَ لَهُمۡ وَيَذۡكُرُواْ ٱسۡمَ ٱللَّهِ فِيٓ أَيَّامٖ مَّعۡلُومَٰتٍ عَلَىٰ مَا رَزَقَهُم مِّنۢ بَهِيمَةِ ٱلۡأَنۡعَٰمِۖ فَكُلُواْ مِنۡهَا وَأَطۡعِمُواْ ٱلۡبَآئِسَ ٱلۡفَقِيرَ\n",
      "\n",
      "6  -->  يَـٰٓأَيُّهَا ٱلَّذِينَ ءَامَنُواْ لَا تَدۡخُلُواْ بُيُوتًا غَيۡرَ بُيُوتِكُمۡ حَتَّىٰ تَسۡتَأۡنِسُواْ وَتُسَلِّمُواْ عَلَىٰٓ أَهۡلِهَاۚ ذَٰلِكُمۡ خَيۡرٞ لَّكُمۡ لَعَلَّكُمۡ تَذَكَّرُونَ\n",
      "\n",
      "7  -->  يَسۡـَٔلُونَكَ مَاذَآ أُحِلَّ لَهُمۡۖ قُلۡ أُحِلَّ لَكُمُ ٱلطَّيِّبَٰتُ وَمَا عَلَّمۡتُم مِّنَ ٱلۡجَوَارِحِ مُكَلِّبِينَ تُعَلِّمُونَهُنَّ مِمَّا عَلَّمَكُمُ ٱللَّهُۖ فَكُلُواْ مِمَّآ أَمۡسَكۡنَ عَلَيۡكُمۡ وَٱذۡكُرُواْ ٱسۡمَ ٱللَّهِ عَلَيۡهِۖ وَٱتَّقُواْ ٱللَّهَۚ إِنَّ ٱللَّهَ سَرِيعُ ٱلۡحِسَابِ\n",
      "\n",
      "8  -->  ۞وَٱذۡكُرُواْ ٱللَّهَ فِيٓ أَيَّامٖ مَّعۡدُودَٰتٖۚ فَمَن تَعَجَّلَ فِي يَوۡمَيۡنِ فَلَآ إِثۡمَ عَلَيۡهِ وَمَن تَأَخَّرَ فَلَآ إِثۡمَ عَلَيۡهِۖ لِمَنِ ٱتَّقَىٰۗ وَٱتَّقُواْ ٱللَّهَ وَٱعۡلَمُوٓاْ أَنَّكُمۡ إِلَيۡهِ تُحۡشَرُونَ\n",
      "\n",
      "9  -->  فَسِيحُواْ فِي ٱلۡأَرۡضِ أَرۡبَعَةَ أَشۡهُرٖ وَٱعۡلَمُوٓاْ أَنَّكُمۡ غَيۡرُ مُعۡجِزِي ٱللَّهِ وَأَنَّ ٱللَّهَ مُخۡزِي ٱلۡكَٰفِرِينَ\n",
      "\n",
      "10  -->  يَـٰٓأَيُّهَا ٱلَّذِينَ ءَامَنُواْ لَا تَقۡتُلُواْ ٱلصَّيۡدَ وَأَنتُمۡ حُرُمٞۚ وَمَن قَتَلَهُۥ مِنكُم مُّتَعَمِّدٗا فَجَزَآءٞ مِّثۡلُ مَا قَتَلَ مِنَ ٱلنَّعَمِ يَحۡكُمُ بِهِۦ ذَوَا عَدۡلٖ مِّنكُمۡ هَدۡيَۢا بَٰلِغَ ٱلۡكَعۡبَةِ أَوۡ كَفَّـٰرَةٞ طَعَامُ مَسَٰكِينَ أَوۡ عَدۡلُ ذَٰلِكَ صِيَامٗا لِّيَذُوقَ وَبَالَ أَمۡرِهِۦۗ عَفَا ٱللَّهُ عَمَّا سَلَفَۚ وَمَنۡ عَادَ فَيَنتَقِمُ ٱللَّهُ مِنۡهُۚ وَٱللَّهُ عَزِيزٞ ذُو ٱنتِقَامٍ\n",
      "\n",
      "11  -->  إِنَّمَآ أُمِرۡتُ أَنۡ أَعۡبُدَ رَبَّ هَٰذِهِ ٱلۡبَلۡدَةِ ٱلَّذِي حَرَّمَهَا وَلَهُۥ كُلُّ شَيۡءٖۖ وَأُمِرۡتُ أَنۡ أَكُونَ مِنَ ٱلۡمُسۡلِمِينَ\n",
      "\n",
      "12  -->  ۞وَٱعۡبُدُواْ ٱللَّهَ وَلَا تُشۡرِكُواْ بِهِۦ شَيۡـٔٗاۖ وَبِٱلۡوَٰلِدَيۡنِ إِحۡسَٰنٗا وَبِذِي ٱلۡقُرۡبَىٰ وَٱلۡيَتَٰمَىٰ وَٱلۡمَسَٰكِينِ وَٱلۡجَارِ ذِي ٱلۡقُرۡبَىٰ وَٱلۡجَارِ ٱلۡجُنُبِ وَٱلصَّاحِبِ بِٱلۡجَنۢبِ وَٱبۡنِ ٱلسَّبِيلِ وَمَا مَلَكَتۡ أَيۡمَٰنُكُمۡۗ إِنَّ ٱللَّهَ لَا يُحِبُّ مَن كَانَ مُخۡتَالٗا فَخُورًا\n",
      "\n",
      "13  -->  وَقَالُواْ ٱلۡحَمۡدُ لِلَّهِ ٱلَّذِيٓ أَذۡهَبَ عَنَّا ٱلۡحَزَنَۖ إِنَّ رَبَّنَا لَغَفُورٞ شَكُورٌ\n",
      "\n",
      "14  -->  إِنَّمَا جُعِلَ ٱلسَّبۡتُ عَلَى ٱلَّذِينَ ٱخۡتَلَفُواْ فِيهِۚ وَإِنَّ رَبَّكَ لَيَحۡكُمُ بَيۡنَهُمۡ يَوۡمَ ٱلۡقِيَٰمَةِ فِيمَا كَانُواْ فِيهِ يَخۡتَلِفُونَ\n",
      "\n",
      "15  -->  قَالَ هَٰذِهِۦ نَاقَةٞ لَّهَا شِرۡبٞ وَلَكُمۡ شِرۡبُ يَوۡمٖ مَّعۡلُومٖ\n",
      "\n",
      "16  -->  ٱلَّذِيٓ أَحَلَّنَا دَارَ ٱلۡمُقَامَةِ مِن فَضۡلِهِۦ لَا يَمَسُّنَا فِيهَا نَصَبٞ وَلَا يَمَسُّنَا فِيهَا لُغُوبٞ\n",
      "\n",
      "17  -->  جَنَّـٰتُ عَدۡنٖ يَدۡخُلُونَهَا يُحَلَّوۡنَ فِيهَا مِنۡ أَسَاوِرَ مِن ذَهَبٖ وَلُؤۡلُؤٗاۖ وَلِبَاسُهُمۡ فِيهَا حَرِيرٞ\n",
      "\n",
      "18  -->  لَأُعَذِّبَنَّهُۥ عَذَابٗا شَدِيدًا أَوۡ لَأَاْذۡبَحَنَّهُۥٓ أَوۡ لَيَأۡتِيَنِّي بِسُلۡطَٰنٖ مُّبِينٖ\n",
      "\n",
      "19  -->  يَـٰٓأَيُّهَا ٱلَّذِينَ ءَامَنُواْ لَيَبۡلُوَنَّكُمُ ٱللَّهُ بِشَيۡءٖ مِّنَ ٱلصَّيۡدِ تَنَالُهُۥٓ أَيۡدِيكُمۡ وَرِمَاحُكُمۡ لِيَعۡلَمَ ٱللَّهُ مَن يَخَافُهُۥ بِٱلۡغَيۡبِۚ فَمَنِ ٱعۡتَدَىٰ بَعۡدَ ذَٰلِكَ فَلَهُۥ عَذَابٌ أَلِيمٞ\n",
      "\n",
      "20  -->  وَإِذۡ جَعَلۡنَا ٱلۡبَيۡتَ مَثَابَةٗ لِّلنَّاسِ وَأَمۡنٗا وَٱتَّخِذُواْ مِن مَّقَامِ إِبۡرَٰهِـۧمَ مُصَلّٗىۖ وَعَهِدۡنَآ إِلَىٰٓ إِبۡرَٰهِـۧمَ وَإِسۡمَٰعِيلَ أَن طَهِّرَا بَيۡتِيَ لِلطَّآئِفِينَ وَٱلۡعَٰكِفِينَ وَٱلرُّكَّعِ ٱلسُّجُودِ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def preprocess(text):\n",
    "    import string\n",
    "    import re\n",
    "    import nltk\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    import pickle\n",
    "    \n",
    "    # Stop Words removal\n",
    "    stop_words = set(stopwords.words('arabic'))\n",
    "    arabic_Tashkeel = re.compile(\"\"\"\n",
    "                                ّ    | # Shadda\n",
    "                                َ    | # Fatha\n",
    "                                ً    | # Tanwin Fath\n",
    "                                ُ    | # Damma\n",
    "                                ٌ    | # Tanwin Damm\n",
    "                                ِ    | # Kasra\n",
    "                                ٍ    | # Tanwin Kasr\n",
    "                                ْ    | # Sukun\n",
    "                                ـ    | # Tatwil/Kashida\n",
    "                                ٓ    | # Maddah Above\n",
    "                                ٔ    | # Hamza Above\n",
    "                                ٕ    | # Hamza Below\n",
    "                                ٖ    | # Subscript Alef\n",
    "                                ٗ    | # Inverted Damma\n",
    "                                ٘    | # Mark Noon Ghunna\n",
    "                                ٙ    | # Inverted Damma Below\n",
    "                                ٚ    | # Mark Sideways Noon Ghunna\n",
    "                                ٛ    | # Kasra with Wavy Hamza Below\n",
    "                                ٜ    | # Fatha with Wavy Hamza Above\n",
    "                                ٝ    | # Fatha with Wavy Hamza Below\n",
    "                                ٞ    | # Fatha with Ring\n",
    "                                ٟ    | # Fatha with Dot Above\n",
    "                            \"\"\", re.VERBOSE)\n",
    "\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words and not any(char.isdigit() for char in word)]\n",
    "\n",
    "    filtered_text = ' '.join(filtered_words)\n",
    "\n",
    "    arabic_punctuation = string.punctuation + '؛،؟«»'\n",
    "\n",
    "    translator = str.maketrans('', '', arabic_punctuation)\n",
    "    filtered_text = filtered_text.translate(translator)\n",
    "\n",
    "    filtered_text = re.sub(arabic_Tashkeel, '', filtered_text)\n",
    "    \n",
    "    text = filtered_text\n",
    "    \n",
    "    # Lemmatizing\n",
    "    import qalsadi.lemmatizer\n",
    "    lemmer = qalsadi.lemmatizer.Lemmatizer()\n",
    "    lemmas = lemmer.lemmatize_text(text)\n",
    "    text = \" \".join(lemmas)\n",
    "    \n",
    "    # Feature Extraction\n",
    "    \n",
    "    from keras.preprocessing.sequence import pad_sequences\n",
    "    with open(base+'/tokenizer.pickle', 'rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n",
    "   \n",
    "    text = [text]\n",
    "    sequences = tokenizer.texts_to_sequences(text)\n",
    "    padded_sequences = pad_sequences(sequences, maxlen=5)\n",
    "    return padded_sequences\n",
    "\n",
    "def rank_N_verse(output_list,N):\n",
    "    import numpy as np\n",
    "    flat_array = np.concatenate(output_list)\n",
    "    \n",
    "    top_100_indices = np.argsort(flat_array)[-N:][::-1]\n",
    "    \n",
    "    # Loading the encoder\n",
    "    import pickle\n",
    "    with open(base+'/onehot_encoder.pkl', 'rb') as handle:\n",
    "        encoder = pickle.load(handle)\n",
    "    \n",
    "    top_N_verse = []\n",
    "    for index in top_100_indices:\n",
    "        encoded = np.zeros(6062)\n",
    "        encoded[index] = 1\n",
    "        verse = encoder.inverse_transform(encoded.reshape(1,-1))\n",
    "        top_N_verse.append(str(verse[0][0]))\n",
    "    \n",
    "    return top_N_verse\n",
    "\n",
    "# Loading the saved model\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(base+'/Lstm_model_100epochs.h5')\n",
    "\n",
    "test_case = input(\"Enter your input : \")\n",
    "\n",
    "features = preprocess(test_case)\n",
    "# print(\"Extracted Features --> \",features)\n",
    "\n",
    "last_dense_output = model.predict(features)\n",
    "\n",
    "top_N_verse = rank_N_verse(last_dense_output,20)\n",
    "i = 1\n",
    "for verse in top_N_verse:\n",
    "    print(i,' --> ',verse)\n",
    "    print()\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b10660f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4443062,
     "sourceId": 8007475,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
